{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5983583d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loading/processing the images  \n",
    "from keras.preprocessing.image import load_img \n",
    "from keras.preprocessing.image import img_to_array \n",
    "from keras.applications.vgg16 import preprocess_input \n",
    "\n",
    "# models \n",
    "from keras.applications.vgg16 import VGG16 \n",
    "from keras.models import Model\n",
    "\n",
    "# clustering and dimension reduction\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# for everything else\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7127a1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0001.png', '0002.png', '0003.png', '0004.png', '0005.png', '0006.png', '0007.png', '0008.png', '0009.png', '0010.png']\n"
     ]
    }
   ],
   "source": [
    "path = r\"D:/trial/dataset1/flower_images/flower_images\"\n",
    "# change the working directory to the path where the images are located\n",
    "os.chdir(path)\n",
    "\n",
    "# this list holds all the image filename\n",
    "flowers = []\n",
    "\n",
    "# creates a ScandirIterator aliased as files\n",
    "with os.scandir(path) as files:\n",
    "  # loops through each file in the directory\n",
    "    for file in files:\n",
    "        if file.name.endswith('.png'):\n",
    "          # adds only the image files to the flowers list\n",
    "            flowers.append(file.name)\n",
    "            \n",
    "print(flowers[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8709473c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load the image as a 224x224 array\n",
    "# img = load_img(flowers[0], target_size=(224,224))\n",
    "# img = np.array(img)\n",
    "\n",
    "# print(img.shape)\n",
    "\n",
    "# reshaped_img = img.reshape(1,224,224,3)\n",
    "# print(reshaped_img.shape)\n",
    "\n",
    "# x = preprocess_input(reshaped_img)\n",
    "\n",
    "# model = VGG16()\n",
    "# # remove the output layer\n",
    "# model = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n",
    "\n",
    "# features = model.predict(x)\n",
    "# print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfdb9e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16()\n",
    "model = Model(inputs = model.inputs, outputs = model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "323a581d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file, model):\n",
    "    # load the image as a 224x224 array\n",
    "    img = load_img(file, target_size=(224,224))\n",
    "    # convert from 'PIL.Image.Image' to numpy array\n",
    "    img = np.array(img) \n",
    "    # reshape the data for the model reshape(num_of_samples, dim 1, dim 2, channels)\n",
    "    reshaped_img = img.reshape(1,224,224,3) \n",
    "    # prepare image for model\n",
    "    imgx = preprocess_input(reshaped_img)\n",
    "    # get the feature vector\n",
    "    features = model.predict(imgx, use_multiprocessing=True)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe9ee59f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210, 1, 4096)\n",
      "(210, 4096)\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "p = r\"D:/trial/flower_features.pkl\"\n",
    "\n",
    "# lop through each image in the dataset\n",
    "for flower in flowers:\n",
    "    # try to extract the features and update the dictionary\n",
    "    try:\n",
    "        feat = extract_features(flower,model)\n",
    "        data[flower] = feat\n",
    "    # if something fails, save the extracted features as a pickle file (optional)\n",
    "    except:\n",
    "        with open(p,'wb') as file:\n",
    "            pickle.dump(data,file)\n",
    "            \n",
    "\n",
    "# get a list of the filenames\n",
    "filenames = np.array(list(data.keys()))\n",
    "\n",
    "# get a list of just the features\n",
    "feat = np.array(list(data.values()))\n",
    "print(feat.shape)\n",
    "\n",
    "#reshape so that there are 210 samples of 4096 vectors\n",
    "feat = feat.reshape(-1,4096)\n",
    "print(feat.shape)\n",
    "\n",
    "# get the unique labels (from the flower_labels.csv)\n",
    "df = pd.read_csv('flower_labels.csv')\n",
    "label = df['label'].tolist()\n",
    "unique_labels = list(set(label))\n",
    "print(unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50c9230a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=100, random_state=22)\n",
    "pca.fit(feat)\n",
    "x = pca.transform(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27089739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Components before PCA:  4096\n",
      "Components after PCA:  100\n"
     ]
    }
   ],
   "source": [
    "print(\"Components before PCA: \", feat.shape[1])\n",
    "print(\"Components after PCA: \", pca.n_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b124ff6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 6, 8, 1, 1, 9, 4, 1, 0, 1, 4, 6, 6, 7, 7, 9, 6, 1, 4, 4, 8, 2,\n",
       "       7, 8, 4, 5, 8, 4, 3, 6, 6, 5, 4, 4, 3, 0, 4, 6, 8, 1, 6, 6, 7, 6,\n",
       "       9, 2, 7, 6, 0, 9, 3, 2, 7, 6, 6, 5, 4, 1, 4, 0, 8, 9, 7, 7, 1, 4,\n",
       "       6, 6, 8, 2, 4, 7, 6, 9, 4, 6, 5, 4, 0, 3, 9, 2, 3, 6, 1, 4, 8, 2,\n",
       "       5, 2, 7, 9, 4, 8, 9, 4, 6, 6, 0, 6, 9, 8, 2, 4, 9, 8, 0, 4, 0, 6,\n",
       "       4, 2, 8, 6, 4, 6, 0, 5, 1, 1, 4, 8, 2, 4, 9, 6, 8, 6, 0, 5, 4, 8,\n",
       "       9, 2, 4, 0, 1, 5, 8, 2, 9, 2, 6, 4, 8, 7, 6, 2, 9, 3, 8, 2, 7, 4,\n",
       "       9, 5, 3, 4, 3, 6, 4, 9, 3, 8, 0, 8, 7, 9, 9, 4, 9, 9, 3, 9, 0, 4,\n",
       "       9, 2, 8, 7, 6, 4, 0, 8, 6, 6, 6, 0, 3, 8, 2, 7, 9, 4, 0, 3, 5, 4,\n",
       "       8, 2, 3, 6, 4, 6, 2, 3, 1, 2, 6, 3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=len(unique_labels), random_state=22)\n",
    "kmeans.fit(x)\n",
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d8d0079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0009.png',\n",
       " '0036.png',\n",
       " '0049.png',\n",
       " '0060.png',\n",
       " '0079.png',\n",
       " '0099.png',\n",
       " '0107.png',\n",
       " '0109.png',\n",
       " '0117.png',\n",
       " '0129.png',\n",
       " '0136.png',\n",
       " '0165.png',\n",
       " '0175.png',\n",
       " '0183.png',\n",
       " '0188.png',\n",
       " '0195.png']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups = {}\n",
    "for file, cluster in zip(filenames,kmeans.labels_):\n",
    "    if cluster not in groups.keys():\n",
    "        groups[cluster] = []\n",
    "        groups[cluster].append(file)\n",
    "    else:\n",
    "        groups[cluster].append(file)\n",
    "\n",
    "# filenames in cluster 0\n",
    "groups[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e71e8132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0022.png',\n",
       " '0046.png',\n",
       " '0052.png',\n",
       " '0070.png',\n",
       " '0082.png',\n",
       " '0088.png',\n",
       " '0090.png',\n",
       " '0103.png',\n",
       " '0112.png',\n",
       " '0123.png',\n",
       " '0134.png',\n",
       " '0140.png',\n",
       " '0142.png',\n",
       " '0148.png',\n",
       " '0152.png',\n",
       " '0178.png',\n",
       " '0191.png',\n",
       " '0200.png',\n",
       " '0205.png',\n",
       " '0208.png']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10ffa00",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ede83b2",
   "metadata": {},
   "source": [
    "## For original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c20b755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loading/processing the images  \n",
    "from keras.preprocessing.image import load_img \n",
    "from keras.preprocessing.image import img_to_array \n",
    "from keras.applications.vgg16 import preprocess_input \n",
    "\n",
    "# models \n",
    "from keras.applications.vgg16 import VGG16 \n",
    "from keras.models import Model\n",
    "\n",
    "# clustering and dimension reduction\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# for everything else\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7fd1d7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"D:/trial/dataset\"\n",
    "# change the working directory to the path where the images are located\n",
    "os.chdir(path)\n",
    "\n",
    "# this list holds all the image filename\n",
    "imgs = []\n",
    "count = 0\n",
    "# creates a ScandirIterator aliased as files\n",
    "with os.scandir(path) as files:\n",
    "  # loops through each file in the directory\n",
    "    for file in files:\n",
    "        if file.name.endswith('.JPEG'):\n",
    "          # adds only the image files to the flowers list\n",
    "            imgs.append(file.name)\n",
    "#         count += 1 \n",
    "        \n",
    "# print(count)\n",
    "# print(flowers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eda17d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16()\n",
    "model = Model(inputs = model.inputs, outputs = model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c49f30c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file, model):\n",
    "    # load the image as a 224x224 array\n",
    "    img = load_img(file, target_size=(224,224))\n",
    "    # convert from 'PIL.Image.Image' to numpy array\n",
    "    img = np.array(img) \n",
    "    # reshape the data for the model reshape(num_of_samples, dim 1, dim 2, channels)\n",
    "    reshaped_img = img.reshape(1,224,224,3) \n",
    "    # prepare image for model\n",
    "    imgx = preprocess_input(reshaped_img)\n",
    "    # get the feature vector\n",
    "    features = model.predict(imgx, use_multiprocessing=True)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "59c4c0ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1582, 1, 4096)\n",
      "(1582, 4096)\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "p = r\"D:/trial/flower_features.pkl\"\n",
    "\n",
    "# lop through each image in the dataset\n",
    "for img in imgs:\n",
    "    # try to extract the features and update the dictionary\n",
    "    try:\n",
    "        feat = extract_features(img,model)\n",
    "        data[img] = feat\n",
    "    # if something fails, save the extracted features as a pickle file (optional)\n",
    "    except:\n",
    "        with open(p,'wb') as file:\n",
    "            pickle.dump(data,file)\n",
    "            \n",
    "\n",
    "# get a list of the filenames\n",
    "filenames = np.array(list(data.keys()))\n",
    "\n",
    "# get a list of just the features\n",
    "feat = np.array(list(data.values()))\n",
    "print(feat.shape)\n",
    "\n",
    "#reshape so that there are 210 samples of 4096 vectors\n",
    "feat = feat.reshape(-1,4096)\n",
    "print(feat.shape)\n",
    "\n",
    "# get the unique labels (from the flower_labels.csv)\n",
    "df = pd.read_csv('D:/trial/class_labels.csv')\n",
    "label = df['unique_id'].tolist()\n",
    "unique_labels = list(set(label))\n",
    "# print(unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88a77bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=100, random_state=22)\n",
    "pca.fit(feat)\n",
    "x = pca.transform(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9aa16a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Components before PCA:  4096\n",
      "Components after PCA:  100\n"
     ]
    }
   ],
   "source": [
    "print(\"Components before PCA: \", feat.shape[1])\n",
    "print(\"Components after PCA: \", pca.n_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b30f4a92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([116, 369, 695, ..., 118, 413, 251])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=len(unique_labels), random_state=22)\n",
    "kmeans.fit(x)\n",
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "833f61c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filenames' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-15e2b38f5fd8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mgroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcluster\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkmeans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcluster\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mgroups\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcluster\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mgroups\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcluster\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'filenames' is not defined"
     ]
    }
   ],
   "source": [
    "groups = {}\n",
    "for file, cluster in zip(filenames,kmeans.labels_):\n",
    "    if cluster not in groups.keys():\n",
    "        groups[cluster] = []\n",
    "        groups[cluster].append(file)\n",
    "    else:\n",
    "        groups[cluster].append(file)\n",
    "\n",
    "# filenames in cluster 0\n",
    "groups[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4de1bd",
   "metadata": {},
   "source": [
    "## After applying PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "88cf0343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loading/processing the images  \n",
    "from keras.preprocessing.image import load_img \n",
    "from keras.preprocessing.image import img_to_array \n",
    "from keras.applications.vgg16 import preprocess_input \n",
    "\n",
    "# models \n",
    "from keras.applications.vgg16 import VGG16 \n",
    "from keras.models import Model\n",
    "\n",
    "# clustering and dimension reduction\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# for everything else\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "86c20650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1618\n",
      "['image00000.jpeg', 'image00001.jpeg', 'image00002.jpeg', 'image00003.jpeg', 'image00004.jpeg', 'image00005.jpeg', 'image00006.jpeg', 'image00007.jpeg', 'image00008.jpeg', 'image00009.jpeg']\n"
     ]
    }
   ],
   "source": [
    "path1 = r\"D:/trial/OUTPUT/pca\"\n",
    "# change the working directory to the path where the images are located\n",
    "os.chdir(path1)\n",
    "\n",
    "# this list holds all the image filename\n",
    "pca_imgs = []\n",
    "count = 0\n",
    "# creates a ScandirIterator aliased as files\n",
    "with os.scandir(path1) as files1:\n",
    "#   loops through each file in the directory\n",
    "    for file1 in files1:\n",
    "        if file1.name.endswith('.jpeg'):\n",
    "          # adds only the image files to the flowers list\n",
    "            pca_imgs.append(file1.name)\n",
    "        count += 1 \n",
    "        \n",
    "print(count)\n",
    "print(pca_imgs[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a5092d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16()\n",
    "model = Model(inputs = model.inputs, outputs = model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3e38f8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file, model):\n",
    "    # load the image as a 224x224 array\n",
    "    img = load_img(file, target_size=(224,224))\n",
    "    # convert from 'PIL.Image.Image' to numpy array\n",
    "    img = np.array(img) \n",
    "    # reshape the data for the model reshape(num_of_samples, dim 1, dim 2, channels)\n",
    "    reshaped_img = img.reshape(1,224,224,3) \n",
    "    # prepare image for model\n",
    "    imgx = preprocess_input(reshaped_img)\n",
    "    # get the feature vector\n",
    "    features = model.predict(imgx, use_multiprocessing=True)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4b553a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1618, 1, 4096)\n",
      "(1618, 4096)\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "p = r\"D:/trial/pca_features.pkl\"\n",
    "\n",
    "# lop through each image in the dataset\n",
    "for pca_img in pca_imgs:\n",
    "    # try to extract the features and update the dictionary\n",
    "    try:\n",
    "        feat = extract_features(pca_img,model)\n",
    "        data[pca_img] = feat\n",
    "    # if something fails, save the extracted features as a pickle file (optional)\n",
    "    except:\n",
    "        with open(p,'wb') as file:\n",
    "            pickle.dump(data,file)\n",
    "            \n",
    "\n",
    "# get a list of the filenames\n",
    "filenames = np.array(list(data.keys()))\n",
    "\n",
    "# get a list of just the features\n",
    "feat = np.array(list(data.values()))\n",
    "print(feat.shape)\n",
    "\n",
    "#reshape so that there are 210 samples of 4096 vectors\n",
    "feat = feat.reshape(-1,4096)\n",
    "print(feat.shape)\n",
    "\n",
    "# get the unique labels (from the flower_labels.csv)\n",
    "df = pd.read_csv('D:/trial/class_labels.csv')\n",
    "label = df['unique_id'].tolist()\n",
    "unique_labels = list(set(label))\n",
    "# print(unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "918f2ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=60, random_state=22)\n",
    "pca.fit(feat)\n",
    "x = pca.transform(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9bfcaab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Components before PCA:  4096\n",
      "Components after PCA:  60\n"
     ]
    }
   ],
   "source": [
    "print(\"Components before PCA: \", feat.shape[1])\n",
    "print(\"Components after PCA: \", pca.n_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fceba72d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([151, 291, 191, ..., 707, 287, 856])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=len(unique_labels), random_state=22)\n",
    "kmeans.fit(x)\n",
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "142a4b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['image00194.jpeg',\n",
       " 'image00217.jpeg',\n",
       " 'image00237.jpeg',\n",
       " 'image00239.jpeg',\n",
       " 'image00833.jpeg',\n",
       " 'image01000.jpeg',\n",
       " 'image01126.jpeg']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups = {}\n",
    "for file, cluster in zip(filenames,kmeans.labels_):\n",
    "    if cluster not in groups.keys():\n",
    "        groups[cluster] = []\n",
    "        groups[cluster].append(file)\n",
    "    else:\n",
    "        groups[cluster].append(file)\n",
    "\n",
    "# filenames in cluster 0\n",
    "groups[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26d5368",
   "metadata": {},
   "source": [
    "## After applying noise removal on output of PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7b387ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loading/processing the images  \n",
    "from keras.preprocessing.image import load_img \n",
    "from keras.preprocessing.image import img_to_array \n",
    "from keras.applications.vgg16 import preprocess_input \n",
    "\n",
    "# models \n",
    "from keras.applications.vgg16 import VGG16 \n",
    "from keras.models import Model\n",
    "\n",
    "# clustering and dimension reduction\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# for everything else\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "54716331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1618\n",
      "['image01618.jpeg', 'image01619.jpeg', 'image01620.jpeg', 'image01621.jpeg', 'image01622.jpeg', 'image01623.jpeg', 'image01624.jpeg', 'image01625.jpeg', 'image01626.jpeg', 'image01627.jpeg']\n"
     ]
    }
   ],
   "source": [
    "path2 = r\"D:/trial/OUTPUT/noise-removed-pca\"\n",
    "# change the working directory to the path where the images are located\n",
    "os.chdir(path2)\n",
    "\n",
    "# this list holds all the image filename\n",
    "no_noise_imgs = []\n",
    "count = 0\n",
    "# creates a ScandirIterator aliased as files\n",
    "with os.scandir(path2) as files2:\n",
    "#   loops through each file in the directory\n",
    "    for file2 in files2:\n",
    "        if file2.name.endswith('.jpeg'):\n",
    "          # adds only the image files to the flowers list\n",
    "            no_noise_imgs.append(file2.name)\n",
    "        count += 1 \n",
    "        \n",
    "print(count)\n",
    "print(no_noise_imgs[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f0a45187",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16()\n",
    "model = Model(inputs = model.inputs, outputs = model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7b758c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file, model):\n",
    "    # load the image as a 224x224 array\n",
    "    img = load_img(file, target_size=(224,224))\n",
    "    # convert from 'PIL.Image.Image' to numpy array\n",
    "    img = np.array(img) \n",
    "    # reshape the data for the model reshape(num_of_samples, dim 1, dim 2, channels)\n",
    "    reshaped_img = img.reshape(1,224,224,3) \n",
    "    # prepare image for model\n",
    "    imgx = preprocess_input(reshaped_img)\n",
    "    # get the feature vector\n",
    "    features = model.predict(imgx, use_multiprocessing=True)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7ac89d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1618, 1, 4096)\n",
      "(1618, 4096)\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "p = r\"D:/trial/no_noise_features.pkl\"\n",
    "\n",
    "# lop through each image in the dataset\n",
    "for no_noise_img in no_noise_imgs:\n",
    "    # try to extract the features and update the dictionary\n",
    "    try:\n",
    "        feat = extract_features(no_noise_img,model)\n",
    "        data[no_noise_img] = feat\n",
    "    # if something fails, save the extracted features as a pickle file (optional)\n",
    "    except:\n",
    "        with open(p,'wb') as file:\n",
    "            pickle.dump(data,file)\n",
    "            \n",
    "\n",
    "# get a list of the filenames\n",
    "filenames = np.array(list(data.keys()))\n",
    "\n",
    "# get a list of just the features\n",
    "feat = np.array(list(data.values()))\n",
    "print(feat.shape)\n",
    "\n",
    "#reshape so that there are 210 samples of 4096 vectors\n",
    "feat = feat.reshape(-1,4096)\n",
    "print(feat.shape)\n",
    "\n",
    "# get the unique labels (from the flower_labels.csv)\n",
    "df = pd.read_csv('D:/trial/class_labels.csv')\n",
    "label = df['unique_id'].tolist()\n",
    "unique_labels = list(set(label))\n",
    "# print(unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "449b2b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=60, random_state=22)\n",
    "pca.fit(feat)\n",
    "x = pca.transform(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6f611a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Components before PCA:  4096\n",
      "Components after PCA:  60\n"
     ]
    }
   ],
   "source": [
    "print(\"Components before PCA: \", feat.shape[1])\n",
    "print(\"Components after PCA: \", pca.n_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a829d2e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([609, 207, 669, ..., 231, 610, 393])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=len(unique_labels), random_state=22)\n",
    "kmeans.fit(x)\n",
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e082d172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['image03203.jpeg',\n",
       " 'image03212.jpeg',\n",
       " 'image03221.jpeg',\n",
       " 'image03228.jpeg',\n",
       " 'image03233.jpeg']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups = {}\n",
    "for file, cluster in zip(filenames,kmeans.labels_):\n",
    "    if cluster not in groups.keys():\n",
    "        groups[cluster] = []\n",
    "        groups[cluster].append(file)\n",
    "    else:\n",
    "        groups[cluster].append(file)\n",
    "\n",
    "# filenames in cluster 0\n",
    "groups[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af72d84",
   "metadata": {},
   "source": [
    "## Only resized and grayscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7390d9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1618\n",
      "['image00000.jpeg', 'image00001.jpeg', 'image00002.jpeg', 'image00003.jpeg', 'image00004.jpeg', 'image00005.jpeg', 'image00006.jpeg', 'image00007.jpeg', 'image00008.jpeg', 'image00009.jpeg']\n"
     ]
    }
   ],
   "source": [
    "path3 = r\"D:/trial/OUTPUT/resized\"\n",
    "# change the working directory to the path where the images are located\n",
    "os.chdir(path3)\n",
    "\n",
    "# this list holds all the image filename\n",
    "resized_imgs = []\n",
    "count = 0\n",
    "# creates a ScandirIterator aliased as files\n",
    "with os.scandir(path3) as files3:\n",
    "#   loops through each file in the directory\n",
    "    for file3 in files3:\n",
    "        if file3.name.endswith('.jpeg'):\n",
    "          # adds only the image files to the flowers list\n",
    "            resized_imgs.append(file3.name)\n",
    "        count += 1 \n",
    "        \n",
    "print(count)\n",
    "print(resized_imgs[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "816df38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16()\n",
    "model = Model(inputs = model.inputs, outputs = model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "46c1ea02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file, model):\n",
    "    # load the image as a 224x224 array\n",
    "    img = load_img(file, target_size=(224,224))\n",
    "    # convert from 'PIL.Image.Image' to numpy array\n",
    "    img = np.array(img) \n",
    "    # reshape the data for the model reshape(num_of_samples, dim 1, dim 2, channels)\n",
    "    reshaped_img = img.reshape(1,224,224,3) \n",
    "    # prepare image for model\n",
    "    imgx = preprocess_input(reshaped_img)\n",
    "    # get the feature vector\n",
    "    features = model.predict(imgx, use_multiprocessing=True)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7e6aa468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1618, 1, 4096)\n",
      "(1618, 4096)\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "p = r\"D:/trial/resized_features.pkl\"\n",
    "\n",
    "# lop through each image in the dataset\n",
    "for resized_img in resized_imgs:\n",
    "    # try to extract the features and update the dictionary\n",
    "    try:\n",
    "        feat = extract_features(resized_img,model)\n",
    "        data[resized_img] = feat\n",
    "    # if something fails, save the extracted features as a pickle file (optional)\n",
    "    except:\n",
    "        with open(p,'wb') as file:\n",
    "            pickle.dump(data,file)\n",
    "            \n",
    "\n",
    "# get a list of the filenames\n",
    "filenames = np.array(list(data.keys()))\n",
    "\n",
    "# get a list of just the features\n",
    "feat = np.array(list(data.values()))\n",
    "print(feat.shape)\n",
    "\n",
    "#reshape so that there are 210 samples of 4096 vectors\n",
    "feat = feat.reshape(-1,4096)\n",
    "print(feat.shape)\n",
    "\n",
    "# get the unique labels (from the flower_labels.csv)\n",
    "df = pd.read_csv('D:/trial/class_labels.csv')\n",
    "label = df['unique_id'].tolist()\n",
    "unique_labels = list(set(label))\n",
    "# print(unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "06d2d08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=60, random_state=22)\n",
    "pca.fit(feat)\n",
    "x = pca.transform(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "78cf416a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Components before PCA:  4096\n",
      "Components after PCA:  60\n"
     ]
    }
   ],
   "source": [
    "print(\"Components before PCA: \", feat.shape[1])\n",
    "print(\"Components after PCA: \", pca.n_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "665bcbdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[744, 10, 413, 10, 372, 290, 674, 290, 266, 237, 266, 295, 266, 237, 10, 730, 964, 266, 956, 675, 237, 288, 675, 674, 674, 230, 399, 945, 290, 266, 705, 10, 456, 266, 39, 461, 558, 413, 503, 503, 503, 242, 541, 242, 149, 160, 585, 39, 288, 737, 704, 161, 149, 607, 91, 860, 405, 753, 558, 780, 597, 126, 160, 763, 383, 614, 787, 700, 645, 161, 313, 937, 106, 361, 801, 372, 313, 313, 313, 313, 937, 372, 849, 106, 149, 796, 313, 196, 149, 313, 39, 23, 447, 849, 624, 709, 194, 313, 194, 313, 593, 196, 313, 372, 937, 675, 456, 326, 149, 148, 194, 38, 645, 384, 849, 80, 4, 643, 395, 849, 675, 820, 149, 83, 148, 732, 643, 643, 4, 148, 329, 332, 948, 372, 536, 129, 82, 873, 643, 494, 240, 849, 911, 148, 332, 606, 240, 148, 326, 888, 849, 26, 430, 313, 643, 26, 937, 935, 937, 675, 129, 149, 240, 129, 38, 100, 828, 795, 80, 262, 432, 935, 262, 767, 167, 332, 100, 174, 536, 106, 911, 38, 313, 911, 849, 38, 26, 911, 198, 332, 23, 592, 603, 641, 580, 435, 844, 240, 650, 498, 886, 723, 168, 791, 982, 240, 262, 136, 590, 762, 650, 552, 418, 659, 830, 675, 3, 675, 473, 768, 240, 73, 39, 342, 115, 194, 405, 209, 651, 432, 73, 921, 240, 673, 115, 194, 983, 115, 618, 115, 372, 209, 849, 115, 639, 107, 786, 346, 42, 257, 193, 549, 379, 107, 42, 369, 653, 70, 107, 355, 601, 440, 261, 379, 363, 369, 107, 634, 889, 469, 978, 364, 6, 685, 376, 376, 559, 13, 477, 57, 211, 291, 696, 853, 415, 989, 379, 813, 99, 107, 261, 107, 99, 10, 352, 954, 426, 52, 510, 195, 49, 52, 172, 370, 515, 116, 738, 467, 797, 930, 110, 352, 172, 116, 605, 569, 87, 217, 87, 171, 987, 87, 87, 987, 540, 445, 337, 706, 171, 87, 445, 190, 864, 519, 987, 307, 987, 516, 32, 337, 445, 142, 785, 302, 75, 445, 445, 71, 896, 190, 13, 13, 14, 32, 67, 171, 715, 176, 340, 578, 72, 75, 165, 289, 130, 371, 316, 620, 783, 458, 782, 69, 323, 72, 321, 472, 156, 437, 165, 87, 305, 650, 109, 550, 165, 307, 629, 598, 892, 936, 392, 582, 868, 901, 217, 281, 442, 947, 286, 625, 942, 138, 138, 583, 190, 793, 637, 79, 496, 708, 852, 445, 18, 109, 406, 307, 903, 25, 615, 406, 550, 109, 267, 286, 903, 154, 182, 995, 751, 498, 548, 341, 751, 574, 349, 190, 366, 325, 553, 560, 341, 959, 400, 187, 227, 751, 895, 506, 401, 867, 799, 154, 366, 807, 147, 16, 842, 1, 778, 604, 32, 217, 138, 596, 596, 752, 1, 908, 972, 18, 66, 64, 66, 130, 468, 428, 556, 13, 987, 729, 755, 680, 147, 307, 67, 271, 159, 687, 757, 339, 345, 627, 179, 502, 269, 448, 474, 839, 858, 445, 621, 845, 72, 788, 975, 928, 271, 962, 669, 32, 695, 72, 109, 246, 159, 489, 683, 890, 877, 547, 836, 789, 328, 915, 308, 122, 576, 988, 428, 199, 458, 922, 199, 199, 852, 44, 950, 246, 276, 159, 546, 356, 32, 89, 89, 78, 227, 652, 646, 251, 336, 78, 271, 7, 25, 55, 920, 859, 50, 396, 371, 728, 240, 737, 806, 322, 636, 371, 658, 336, 991, 78, 371, 156, 278, 371, 72, 743, 385, 987, 932, 249, 30, 56, 353, 376, 114, 631, 711, 327, 655, 739, 72, 241, 241, 943, 464, 724, 608, 154, 130, 72, 353, 385, 638, 318, 427, 389, 427, 318, 143, 427, 427, 27, 527, 817, 146, 359, 27, 72, 48, 682, 550, 427, 707, 238, 475, 497, 173, 143, 825, 427, 348, 427, 564, 27, 140, 749, 385, 697, 834, 924, 898, 108, 968, 320, 693, 29, 720, 717, 182, 944, 635, 926, 694, 111, 881, 446, 144, 718, 137, 347, 144, 726, 226, 320, 347, 50, 287, 76, 588, 185, 588, 792, 588, 76, 504, 458, 588, 264, 875, 555, 264, 204, 249, 76, 317, 931, 76, 303, 76, 594, 204, 594, 792, 249, 264, 509, 513, 267, 700, 664, 296, 588, 204, 62, 990, 594, 668, 105, 990, 21, 105, 887, 113, 354, 8, 504, 8, 792, 460, 498, 47, 977, 264, 239, 363, 54, 245, 184, 861, 424, 678, 294, 630, 185, 90, 511, 507, 929, 792, 90, 803, 72, 486, 368, 933, 596, 130, 520, 101, 542, 939, 47, 504, 579, 500, 21, 310, 960, 217, 460, 596, 990, 688, 133, 335, 610, 500, 105, 362, 435, 545, 105, 906, 792, 105, 633, 360, 919, 531, 754, 234, 698, 531, 53, 534, 186, 166, 279, 957, 223, 809, 112, 170, 848, 177, 628, 223, 619, 177, 811, 9, 62, 263, 459, 367, 425, 306, 641, 866, 946, 86, 375, 662, 74, 68, 470, 68, 449, 238, 714, 124, 86, 201, 502, 596, 866, 86, 435, 436, 82, 43, 36, 524, 976, 700, 438, 710, 357, 94, 702, 125, 117, 268, 120, 934, 557, 94, 330, 967, 94, 382, 145, 626, 893, 421, 383, 169, 602, 958, 761, 613, 584, 197, 222, 586, 272, 181, 11, 837, 970, 276, 882, 145, 405, 393, 28, 883, 222, 67, 197, 268, 2, 84, 761, 976, 535, 2, 169, 802, 2, 94, 11, 537, 169, 255, 483, 882, 710, 537, 301, 192, 95, 95, 855, 275, 543, 152, 969, 722, 992, 758, 275, 632, 483, 95, 586, 221, 201, 499, 644, 522, 311, 95, 152, 95, 152, 238, 609, 925, 82, 850, 976, 408, 689, 126, 247, 589, 733, 780, 774, 589, 35, 141, 829, 253, 253, 180, 571, 218, 155, 288, 660, 938, 981, 118, 465, 247, 288, 491, 118, 585, 253, 491, 665, 285, 83, 146, 585, 955, 408, 904, 80, 645, 585, 270, 721, 243, 824, 482, 971, 126, 488, 315, 880, 745, 258, 162, 595, 260, 672, 414, 324, 779, 865, 676, 770, 163, 50, 233, 315, 771, 163, 573, 595, 17, 315, 214, 654, 478, 274, 821, 387, 15, 686, 431, 773, 773, 656, 213, 97, 838, 727, 334, 46, 735, 213, 81, 487, 200, 641, 521, 974, 198, 213, 46, 316, 666, 952, 386, 46, 39, 119, 405, 677, 84, 298, 617, 386, 595, 431, 151, 851, 568, 419, 120, 595, 205, 127, 815, 731, 595, 178, 298, 663, 999, 46, 12, 484, 794, 532, 248, 773, 61, 236, 914, 417, 826, 623, 31, 229, 405, 810, 104, 742, 626, 856, 681, 626, 884, 377, 104, 493, 514, 236, 104, 191, 254, 191, 444, 31, 31, 862, 517, 123, 444, 73, 765, 12, 73, 333, 765, 191, 320, 765, 38, 420, 277, 765, 528, 149, 304, 734, 123, 765, 716, 444, 611, 455, 444, 885, 74, 674, 561, 12, 963, 273, 212, 373, 225, 229, 228, 344, 136, 480, 822, 966, 551, 505, 857, 228, 863, 98, 781, 479, 857, 410, 233, 137, 869, 843, 927, 233, 60, 212, 490, 818, 433, 402, 670, 577, 344, 175, 98, 876, 31, 764, 225, 434, 405, 481, 819, 344, 596, 12, 405, 175, 833, 358, 212, 691, 350, 259, 587, 212, 0, 481, 450, 452, 512, 0, 899, 63, 857, 13, 612, 869, 462, 34, 33, 235, 34, 840, 386, 34, 77, 311, 565, 28, 314, 725, 381, 220, 684, 910, 539, 103, 45, 961, 961, 905, 565, 756, 311, 45, 33, 533, 537, 923, 416, 572, 103, 398, 412, 300, 210, 224, 365, 311, 816, 33, 912, 562, 951, 134, 846, 565, 280, 800, 164, 82, 164, 777, 338, 463, 748, 900, 338, 457, 65, 679, 878, 713, 219, 812, 996, 412, 338, 276, 265, 591, 297, 909, 661, 741, 215, 37, 454, 973, 297, 409, 622, 902, 471, 24, 24, 316, 97, 750, 222, 390, 759, 312, 316, 390, 535, 153, 127, 127, 918, 96, 206, 51, 280, 701, 640, 390, 282, 37, 5, 596, 132, 224, 993, 28, 224, 74, 404, 907, 883, 67, 5, 871, 883, 224, 535, 125, 5, 535, 667, 224, 386, 314, 907, 125, 570, 567, 314, 6, 740, 85, 986, 390, 523, 192, 268, 74, 283, 980, 205, 314, 997, 835, 804, 411, 770, 85, 314, 311, 775, 84, 314, 183, 374, 466, 746, 530, 374, 965, 476, 128, 563, 433, 88, 538, 984, 518, 453, 913, 537, 319, 529, 907, 662, 958, 314, 874, 135, 879, 28, 319, 391, 423, 134, 132, 600, 125, 600, 492, 274, 583, 423, 575, 74, 439, 747, 403, 214, 375, 158, 798, 501, 250, 214, 575, 306, 284, 674, 575, 790, 501, 647, 439, 250, 544, 501, 917, 357, 206, 276, 854, 498, 656, 832, 570, 419, 583, 72, 712, 97, 388, 994, 894, 153, 206, 407, 690, 701, 772, 872, 54, 96, 973, 891, 429, 648, 829, 64, 331, 897, 841, 3, 441, 847, 581, 92, 276, 671, 343, 441, 203, 351, 157, 232, 953, 205, 642, 699, 805, 784, 394, 292, 3, 203, 378, 916, 102, 218, 441, 657, 484, 870, 599, 905, 485, 525, 188, 153, 54, 525, 784, 207, 441, 808, 41, 456, 985, 256, 202, 93, 252, 59, 998, 299, 128, 131, 827, 216, 940, 93, 299, 231, 88, 40, 59, 760, 58, 58, 703, 196, 22, 132, 181, 277, 293, 719, 58, 150, 320, 314, 616, 208, 831, 208, 293, 649, 22, 397, 703, 502, 189, 703, 36, 380, 769, 703, 132, 941, 277, 554, 277, 979, 823, 566, 20, 451, 309, 495, 495, 736, 776, 422, 121, 121, 19, 526, 19, 233, 244, 508, 121, 19, 692, 19, 139, 766, 121, 19, 814, 121, 692, 19, 19, 19, 244, 443, 244, 433, 19, 19, 139, 949, 19, 139, 19, 244, 121]\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=len(unique_labels), random_state=22)\n",
    "kmeans.fit(x)\n",
    "array = list(kmeans.labels_)\n",
    "print(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9c50250b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['image01585.jpeg',\n",
       " 'image01587.jpeg',\n",
       " 'image01592.jpeg',\n",
       " 'image01594.jpeg',\n",
       " 'image01598.jpeg',\n",
       " 'image01602.jpeg',\n",
       " 'image01603.jpeg',\n",
       " 'image01604.jpeg',\n",
       " 'image01609.jpeg',\n",
       " 'image01610.jpeg',\n",
       " 'image01613.jpeg',\n",
       " 'image01615.jpeg']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups = {}\n",
    "for file, cluster in zip(filenames,kmeans.labels_):\n",
    "    if cluster not in groups.keys():\n",
    "        groups[cluster] = []\n",
    "        groups[cluster].append(file)\n",
    "    else:\n",
    "        groups[cluster].append(file)\n",
    "\n",
    "# filenames in cluster 0\n",
    "groups[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e398ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
